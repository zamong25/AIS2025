"""
ë¸íŒŒì´ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ - ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ëª¨ë“ˆ
API ì‹¤íŒ¨ì‹œ 0ê°’ ëŒ€ì²´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë°ì´í„° ì‹ ë¢°ë„ë¥¼ ê´€ë¦¬
"""

from dataclasses import dataclass
from typing import Dict, Any, Optional, List
from datetime import datetime, timezone
import logging

@dataclass
class DataQuality:
    """ë°ì´í„° í’ˆì§ˆ ì •ë³´"""
    value: Any
    reliable: bool
    confidence: float  # 0.0 ~ 1.0
    source: str
    timestamp: str
    error_message: Optional[str] = None

@dataclass
class QualityReport:
    """ì „ì²´ ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ"""
    overall_confidence: float  # ì „ì²´ ì‹ ë¢°ë„
    reliable_data_count: int
    total_data_count: int
    critical_failures: List[str]
    warnings: List[str]
    data_quality_map: Dict[str, DataQuality]

class DataQualityManager:
    """ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ì"""
    
    # ë°ì´í„°ë³„ ì¤‘ìš”ë„ (critical/high/medium/low)
    DATA_IMPORTANCE = {
        'open_interest': 'high',
        'oi_delta': 'medium', 
        'funding_rate': 'high',
        'btc_dominance': 'medium',
        'btc_correlation': 'medium',
        'price': 'critical',
        'volume': 'critical',
        'ema_20': 'high',
        'ema_50': 'high',
        'rsi': 'high',
        'atr': 'medium',
        'obv': 'medium'
    }
    
    # ì¤‘ìš”ë„ë³„ ìµœì†Œ ì‹ ë¢°ë„ ìš”êµ¬ì‚¬í•­
    MIN_CONFIDENCE_THRESHOLDS = {
        'critical': 0.95,  # 95% ì´ìƒ
        'high': 0.8,       # 80% ì´ìƒ
        'medium': 0.6,     # 60% ì´ìƒ
        'low': 0.4         # 40% ì´ìƒ
    }
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def create_quality_data(self, key: str, value: Any, success: bool, 
                          error_msg: str = None, source: str = "binance") -> DataQuality:
        """í’ˆì§ˆ ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„° ìƒì„±"""
        
        # ì¤‘ìš”ë„ í™•ì¸
        importance = self.DATA_IMPORTANCE.get(key, 'low')
        
        if success:
            # ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°
            confidence = 0.95 if importance == 'critical' else 0.9
            return DataQuality(
                value=value,
                reliable=True,
                confidence=confidence,
                source=source,
                timestamp=datetime.now(timezone.utc).isoformat(),
                error_message=None
            )
        else:
            # ì‹¤íŒ¨í•œ ë°ì´í„° - ì¤‘ìš”ë„ì— ë”°ë¼ ì²˜ë¦¬
            if importance == 'critical':
                # Critical ë°ì´í„°ëŠ” ì‹¤íŒ¨ì‹œ None ë°˜í™˜ (ë¶„ì„ ì¤‘ë‹¨)
                return DataQuality(
                    value=None,
                    reliable=False,
                    confidence=0.0,
                    source=source,
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    error_message=error_msg
                )
            else:
                # Criticalì´ ì•„ë‹Œ ë°ì´í„°ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©í•˜ë˜ ì‹ ë¢°ë„ í‘œì‹œ
                default_value = self._get_safe_default(key)
                return DataQuality(
                    value=default_value,
                    reliable=False,
                    confidence=0.1,  # ë§¤ìš° ë‚®ì€ ì‹ ë¢°ë„
                    source=f"{source}_default",
                    timestamp=datetime.now(timezone.utc).isoformat(),
                    error_message=error_msg
                )
    
    def _get_safe_default(self, key: str) -> Any:
        """ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜ (ì™„ì „íˆ ì„ì˜ê°’ ëŒ€ì‹  ì˜ë¯¸ìˆëŠ” ê¸°ë³¸ê°’)"""
        
        # ë¹„ìœ¨/í¼ì„¼íŠ¸ ê°’ë“¤
        if key in ['oi_delta', 'btc_correlation']:
            return 0.0  # ë³€í™” ì—†ìŒì„ ì˜ë¯¸
        
        # ë„ë¯¸ë„ŒìŠ¤
        elif key == 'btc_dominance':
            return 50.0  # ë¹„íŠ¸ì½”ì¸ ë„ë¯¸ë„ŒìŠ¤ í‰ê· ê°’
        
        # í€ë”©ë¹„
        elif key == 'funding_rate':
            return 0.0001  # ì¼ë°˜ì ì¸ í€ë”©ë¹„
        
        # ê¸°ìˆ ì  ì§€í‘œë“¤
        elif key == 'rsi':
            return 50.0  # ì¤‘ë¦½ RSI
        
        elif key in ['ema_20', 'ema_50', 'price']:
            return None  # Critical ë°ì´í„°ëŠ” ê¸°ë³¸ê°’ ì—†ìŒ
        
        else:
            return 0.0
    
    def validate_data_collection(self, data_map: Dict[str, DataQuality]) -> QualityReport:
        """ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ì¢…í•© ê²€ì¦"""
        
        reliable_count = sum(1 for dq in data_map.values() if dq.reliable)
        total_count = len(data_map)
        
        # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚° (ì¤‘ìš”ë„ ê°€ì¤‘ í‰ê· )
        total_weight = 0
        weighted_confidence = 0
        
        for key, dq in data_map.items():
            importance = self.DATA_IMPORTANCE.get(key, 'low')
            weight = {'critical': 4, 'high': 3, 'medium': 2, 'low': 1}[importance]
            
            total_weight += weight
            weighted_confidence += dq.confidence * weight
        
        overall_confidence = weighted_confidence / total_weight if total_weight > 0 else 0
        
        # Critical ì‹¤íŒ¨ í™•ì¸
        critical_failures = []
        warnings = []
        
        for key, dq in data_map.items():
            importance = self.DATA_IMPORTANCE.get(key, 'low')
            min_confidence = self.MIN_CONFIDENCE_THRESHOLDS[importance]
            
            if dq.confidence < min_confidence:
                if importance == 'critical':
                    critical_failures.append(f"{key}: {dq.error_message or 'Unknown error'}")
                else:
                    warnings.append(f"{key}: ë‚®ì€ ì‹ ë¢°ë„ ({dq.confidence:.2f})")
        
        return QualityReport(
            overall_confidence=overall_confidence,
            reliable_data_count=reliable_count,
            total_data_count=total_count,
            critical_failures=critical_failures,
            warnings=warnings,
            data_quality_map=data_map
        )
    
    def should_proceed_with_analysis(self, quality_report: QualityReport) -> bool:
        """ë¶„ì„ì„ ê³„ì† ì§„í–‰í•´ë„ ë˜ëŠ”ì§€ íŒë‹¨"""
        
        # Critical ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ë¶„ì„ ì¤‘ë‹¨
        if quality_report.critical_failures:
            self.logger.error(f"Critical ë°ì´í„° ì‹¤íŒ¨: {quality_report.critical_failures}")
            return False
        
        # ì „ì²´ ì‹ ë¢°ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë¶„ì„ ì¤‘ë‹¨
        if quality_report.overall_confidence < 0.5:
            self.logger.warning(f"ì „ì²´ ë°ì´í„° ì‹ ë¢°ë„ ë„ˆë¬´ ë‚®ìŒ: {quality_report.overall_confidence:.2f}")
            return False
        
        return True
    
    def extract_values_for_analysis(self, data_map: Dict[str, DataQuality], 
                                  include_unreliable: bool = False) -> Dict[str, Any]:
        """ë¶„ì„ìš© ë°ì´í„° ê°’ ì¶”ì¶œ (ì‹ ë¢°ë„ ì •ë³´ ì œê±°)"""
        
        result = {}
        for key, dq in data_map.items():
            if dq.reliable or include_unreliable:
                if dq.value is not None:
                    result[key] = dq.value
        
        return result
    
    def generate_quality_summary(self, quality_report: QualityReport) -> str:
        """ë°ì´í„° í’ˆì§ˆ ìš”ì•½ ìƒì„±"""
        
        summary = f"""
ğŸ“Š ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ
ì „ì²´ ì‹ ë¢°ë„: {quality_report.overall_confidence:.2%}
ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„°: {quality_report.reliable_data_count}/{quality_report.total_data_count}

"""
        
        if quality_report.critical_failures:
            summary += "ğŸš¨ Critical ì‹¤íŒ¨:\n"
            for failure in quality_report.critical_failures:
                summary += f"  â€¢ {failure}\n"
            summary += "\n"
        
        if quality_report.warnings:
            summary += "âš ï¸ ê²½ê³ ì‚¬í•­:\n"
            for warning in quality_report.warnings:
                summary += f"  â€¢ {warning}\n"
            summary += "\n"
        
        # ë°ì´í„°ë³„ ìƒì„¸ ì •ë³´
        summary += "ğŸ“‹ ë°ì´í„°ë³„ ìƒì„¸ ì •ë³´:\n"
        for key, dq in quality_report.data_quality_map.items():
            status = "âœ…" if dq.reliable else "âŒ"
            summary += f"  {status} {key}: {dq.confidence:.2%} ({dq.source})\n"
        
        return summary


# ì „ì—­ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
data_quality_manager = DataQualityManager()